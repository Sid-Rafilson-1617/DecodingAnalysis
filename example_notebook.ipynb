{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88079d8",
   "metadata": {},
   "source": [
    "# Decoding analysis example notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63214356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from core import *\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "dir = r\"D:\\clickbait-mmz\"\n",
    "save_dir = r\"C:\\Users\\smearlab\\analysis_code\\EncodingModels\\outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17561e",
   "metadata": {},
   "source": [
    "## Setting up an example session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "933c1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up parameters\n",
    "mouse = '6002'\n",
    "session = '6'\n",
    "window_size = 2.0  # seconds\n",
    "step_size = 2  # seconds\n",
    "fs = 30000  # sampling frequency for spike data\n",
    "sfs = 1000  # sampling frequency for sniff data\n",
    "use_units = 'good'  # can be 'all', 'good', or a specific unit number\n",
    "k_CV = 3  # number of cross-validation folds\n",
    "n_blocks = 3\n",
    "shift = 2 # shift for construction of null distribution (0 means no shift)\n",
    "model_input = 'neural'\n",
    "use_behaviors = ['position_x', 'position_y', 'velocity_x', 'velocity_y', 'sns']  # behaviors to use in the model\n",
    "\n",
    "save_dir = os.path.join(save_dir, mouse, session, f'shift_{shift}')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af4c77",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a370fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data to get spike counts, behavioral variables and names, trial IDs, neuron names, and neuron info from manual curation\n",
    "counts, variables, variable_names, trial_ids, neu_names, neu_info = preprocess(dir, save_dir, mouse, session, window_size, step_size, use_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4fea0",
   "metadata": {},
   "source": [
    "***choose which region to analyze from 'OB' or 'HC'***\n",
    "\n",
    "This code also performs the circular shift of the spike rates if shift > 0 for the construction of the null distribution for hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bded1ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling spike rates by 761 time bins\n",
      "spike rates shape (# time bins, # neurons): (917, 29)\n"
     ]
    }
   ],
   "source": [
    "# get the neurons for the correct area\n",
    "use_units = [key for key, value in neu_info.items() if value['area'] == 'HC']\n",
    "spike_rates = counts[:, np.isin(neu_names, use_units)]\n",
    "if shift > 0:\n",
    "    random_roll = np.random.randint(0, spike_rates.shape[0])\n",
    "    print(f'rolling spike rates by {random_roll} time bins')\n",
    "    spike_rates = np.roll(spike_rates, random_roll, axis=0)\n",
    "print(f'spike rates shape (# time bins, # neurons): {spike_rates.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e961be2",
   "metadata": {},
   "source": [
    "***Extracting the behavioral variables***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46e9eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables: ['position_x', 'position_y', 'velocity_x', 'velocity_y', 'sns', 'latency', 'phase', 'speed', 'click']\n",
      "behavior shape (# time bins, # dims): (917, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f'variables: {variable_names}')\n",
    "\n",
    "behavior_components = []\n",
    "if 'position_x' in use_behaviors:\n",
    "    pos_x = np.array(variables[variable_names.index('position_x')])\n",
    "    behavior_components.append(pos_x)\n",
    "\n",
    "if 'position_y' in use_behaviors:\n",
    "    pos_y = np.array(variables[variable_names.index('position_y')])\n",
    "    behavior_components.append(pos_y)\n",
    "\n",
    "if 'velocity_x' in use_behaviors:\n",
    "    vel_x = np.array(variables[variable_names.index('velocity_x')])\n",
    "    behavior_components.append(vel_x)\n",
    "\n",
    "if 'velocity_y' in use_behaviors:\n",
    "    vel_y = np.array(variables[variable_names.index('velocity_y')])\n",
    "    behavior_components.append(vel_y)\n",
    "\n",
    "if 'sns' in use_behaviors:\n",
    "    sniff_rate = np.array(variables[variable_names.index('sns')])\n",
    "    behavior_components.append(sniff_rate)\n",
    "\n",
    "behavior = np.stack(behavior_components, axis=1)\n",
    "print(f'behavior shape (# time bins, # dims): {behavior.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0984f3d",
   "metadata": {},
   "source": [
    "***Building list of arguements to pass to the model***\n",
    "\n",
    "This is where the input $\\bold{X}$ and output $y$ variables for the model are defined.\n",
    "\n",
    "$y = f(\\bold{X})$ where $f(\\cdot)$ is learned from the data to minimize some cost function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "053301ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through the folds of cross-validation to build datasets\n",
    "arg_list = []\n",
    "\n",
    "for k in range(k_CV):\n",
    "    rates_train, rates_test, train_switch_ind, test_switch_ind = cv_split(spike_rates, k, k_CV, n_blocks)\n",
    "    behavior_train, behavior_test, _, _ = cv_split(behavior, k, k_CV, n_blocks)\n",
    "\n",
    "    current_save_path = os.path.join(save_dir, \"model fits\")\n",
    "    os.makedirs(current_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Decide which data to use for input (X) and output (y)\n",
    "    if model_input == 'neural':\n",
    "        y_train = behavior_train\n",
    "        y_test = behavior_test\n",
    "\n",
    "        X_train = rates_train\n",
    "        X_test = rates_test\n",
    "    elif model_input == 'behavioral':\n",
    "        y_train = rates_train\n",
    "        y_test = rates_test\n",
    "\n",
    "        X_train = behavior_train\n",
    "        X_test = behavior_test\n",
    "\n",
    "    arg_list.append((X_train, X_test, y_train, y_test, train_switch_ind, test_switch_ind, current_save_path, None, shift))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b60e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds(targets, predictions, test_switch_ind, sequence_length, save_path, k, shift):\n",
    "    adjusted_test_switch_ind = [ind - sequence_length * k for k, ind in enumerate(test_switch_ind)]\n",
    "    behavior_dim = targets.shape[1]\n",
    "    _, ax = plt.subplots(behavior_dim, 1, figsize=(20, 10), sharex= True)\n",
    "    if behavior_dim == 1:\n",
    "        ax = [ax]\n",
    "    for i in range(behavior_dim):\n",
    "        ax[i].plot(targets[:, i], label='True', color = 'crimson')\n",
    "        ax[i].plot(predictions[:, i], label='Predicted')\n",
    "        for ind in adjusted_test_switch_ind:\n",
    "            ax[i].axvline(ind, color='grey', linestyle = '--', alpha=0.5)\n",
    "\n",
    "    if behavior_dim > 4:\n",
    "        # remove the y-axis ticks \n",
    "        for a in ax:\n",
    "            a.set_yticks([])\n",
    "    plt.xlabel('Time')\n",
    "    ax[0].legend(loc = 'upper right')\n",
    "\n",
    "    sns.despine()\n",
    "    plt.savefig(os.path.join(save_path, f'lstm_predictions_k_{k}_shift_{shift}.png'), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aa20d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(X_train, X_test, y_train, y_test, train_switch_ind, test_switch_ind, current_save_path,\n",
    "        device = None, shift = 0, hidden_dim = 8, num_layers = 2, dropout = 0.1, sequence_length = 3, target_index = -1, \n",
    "        batch_size = 64, lr = 0.01, num_epochs = 300, patience = 10, min_delta = 0.01, factor = 0.5, plot_predictions = True):\n",
    "    \n",
    "    # Set the device\n",
    "    if device:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = device\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Create the model\n",
    "    lstm_model = LSTMDecoder(input_dim= X_train.shape[1], hidden_dim=hidden_dim, output_dim=y_train.shape[1], num_layers=num_layers, dropout = dropout).to(device)\n",
    "\n",
    "\n",
    "    # Prepare the training data for LSTM\n",
    "    blocks = [(train_switch_ind[i], train_switch_ind[i + 1]) for i in range(len(train_switch_ind) - 1)]\n",
    "    train_dataset = SequenceDataset(X_train, y_train, blocks, sequence_length, target_index)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=min(batch_size, len(train_dataset)), shuffle=False, num_workers=0, pin_memory=True, prefetch_factor=None)\n",
    "\n",
    "\n",
    "    # Training the LSTM model\n",
    "    start_train = time.time()\n",
    "    trained_lstm_model, lstm_history = train_LSTM(lstm_model, train_loader, device, lr=lr, epochs=num_epochs, patience=patience, min_delta=min_delta, factor=factor, verbose=False)\n",
    "    print(f\"\\nTraining time: {time.time() - start_train:.2f}s fold={k} shift={shift}\", flush=True)\n",
    "    # Free up memory\n",
    "    del lstm_model, train_dataset, train_loader\n",
    "\n",
    "\n",
    "    # Plot loss\n",
    "    if plot_predictions:\n",
    "        plot_training(lstm_history, current_save_path, shift, k)\n",
    "\n",
    "\n",
    "    # Prepare the test data for LSTM\n",
    "    test_blocks = [(test_switch_ind[i], test_switch_ind[i + 1]) for i in range(len(test_switch_ind) - 1)]\n",
    "    test_dataset = SequenceDataset(X_test, y_test, test_blocks, sequence_length, target_index)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=min(batch_size, len(test_dataset)), num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "    # Predict on the test set\n",
    "    trained_lstm_model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            preds = trained_lstm_model(X_batch)\n",
    "            predictions.append(preds.cpu().numpy())\n",
    "            targets.append(y_batch.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "    # Clean up\n",
    "    del trained_lstm_model, test_dataset, test_loader\n",
    "\n",
    "    plot_preds(targets, predictions, test_switch_ind, sequence_length, current_save_path, k, shift)\n",
    "\n",
    "    diffs = predictions - targets\n",
    "    rmse = np.sqrt(np.mean(diffs ** 2, axis=0))\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Total time {time.time() - start_train:.2f}s for fold={k} shift={shift}\\n\\n\\n\", flush=True)\n",
    "\n",
    "\n",
    "    return rmse, targets, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941f4d4",
   "metadata": {},
   "source": [
    "***Running the model across all the folds and saving the results***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e0c6e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1/3...\n",
      "Using device: cuda\n",
      "\n",
      "Training time: 2.46s fold=0 shift=2\n",
      "Total time 3.69s for fold=0 shift=2\n",
      "\n",
      "\n",
      "\n",
      "Processing fold 2/3...\n",
      "Using device: cuda\n",
      "\n",
      "Training time: 3.38s fold=1 shift=2\n",
      "Total time 5.19s for fold=1 shift=2\n",
      "\n",
      "\n",
      "\n",
      "Processing fold 3/3...\n",
      "Using device: cuda\n",
      "\n",
      "Training time: 2.99s fold=2 shift=2\n",
      "Total time 4.11s for fold=2 shift=2\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "results_save_dir = os.path.join(save_dir, \"results\")\n",
    "os.makedirs(results_save_dir, exist_ok=True)\n",
    "for k in range(k_CV):\n",
    "    print(f\"Processing fold {k + 1}/{k_CV}...\")\n",
    "    rmse, targets, predictions = process_fold(*arg_list[k])\n",
    "\n",
    "    # Define file paths for saving results\n",
    "    results_file = f'results_shift{shift}_fold{k}.npz'\n",
    "    results_path = os.path.join(results_save_dir, results_file)\n",
    "    \n",
    "    # Save rmse as compressed .npz file\n",
    "    np.savez_compressed(results_path, rmse=rmse, targets=targets, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Store just the path in the results table\n",
    "    results.append({\n",
    "        'mouse': mouse,\n",
    "        'session': session,\n",
    "        'shift': shift,\n",
    "        'fold': k,\n",
    "        'results_file': results_file,\n",
    "    })\n",
    "\n",
    "# convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(os.path.join(results_save_dir, 'results.csv'), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747dd4b2",
   "metadata": {},
   "source": [
    "# Statistical analysis to compare the models\n",
    "\n",
    "rmse is a list with n_folds elements, each element is a list with rmse values for each fold. The index of the RMSE value corresponds to the target dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5f46a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of shifts: 2\n",
      "dim 0: true - null RMSE = -14.6328, p-value = 0.0201, statistic = -2.3238\n",
      "dim 1: true - null RMSE = -6.1701, p-value = 0.1967, statistic = -1.2910\n",
      "dim 2: true - null RMSE = -0.0024, p-value = 0.7963, statistic = -0.2582\n",
      "dim 3: true - null RMSE = 0.0127, p-value = 0.4386, statistic = 0.7746\n",
      "dim 4: true - null RMSE = 0.5347, p-value = 0.1213, statistic = 1.5492\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ranksums\n",
    "\n",
    "n_dims = 5\n",
    "\n",
    "session_dir = r\"C:\\Users\\smearlab\\analysis_code\\EncodingModels\\outputs\\6002\\6\"\n",
    "\n",
    "shifts = os.listdir(session_dir)\n",
    "n_shifts = len(shifts)\n",
    "\n",
    "print(f'Number of shifts: {n_shifts - 1}')\n",
    "for dim in range(n_dims):\n",
    "    true_rmse = []\n",
    "    null_rmse = []\n",
    "    for shift in range(n_shifts):\n",
    "        shift_dir = os.path.join(session_dir, f'shift_{shift}', 'results')\n",
    "        n_folds = len([f for f in os.listdir(shift_dir) if f.startswith('results') and f.endswith('.npz')])\n",
    "        for fold in range(n_folds):\n",
    "            rmse = np.load(os.path.join(shift_dir, f'results_shift{shift}_fold{fold}.npz'))['rmse'][dim]\n",
    "\n",
    "            if shift == 0:\n",
    "                true_rmse.append(rmse)\n",
    "            else:\n",
    "                null_rmse.append(rmse)\n",
    "\n",
    "    stat, p = ranksums(true_rmse, null_rmse)\n",
    "    print(f'dim {dim}: true - null RMSE = {np.mean(true_rmse) - np.mean(null_rmse):.4f}, p-value = {p:.4f}, statistic = {stat:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb196a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6ace7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (decoding)",
   "language": "python",
   "name": "decoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
